**LLM Comparison â€” Product Teardown: Zomato**

**Models Used**
| # | LLM Name | Mode | Response Time |
|---|----------|------|--------------|
| 1 | ChatGPT  | Standard | ~10 sec |
| 2 | Gemini   | Pro | ~8 sec |
| 3 | Claude   | Standard | ~12 sec |

## Layer-by-Layer Comparison

### Layer 1: Data Foundation
| Criteria | LLM 1 | LLM 2 | LLM 3 | Best |
|----------|-------|-------|-------|------|
| Specificity (1-5) | 4 | 3 | 5 | LLM 3 |
| Named tech | Y | Y | Y | LLM 3 |
| Challenge identified | Y | N | Y | LLM 3 |
| Notes | ChatGPT good, Claude deeper |

### Layer 2: Statistics
| Criteria | LLM 1 | LLM 2 | LLM 3 | Best |
|----------|-------|-------|-------|------|
| Specificity | 3 | 2 | 4 | LLM 3 |
| Named tech | N | N | Y | LLM 3 |
| Challenge | Y | N | Y | LLM 3 |

### Layer 3: ML Models
| Criteria | LLM 1 | LLM 2 | LLM 3 | Best |
|----------|-------|-------|-------|------|
| Specificity | 4 | 3 | 5 | LLM 3 |
| Named models | Y | Y | Y | LLM 3 |
| Challenge | Y | N | Y | LLM 3 |

### Layer 4: LLM
| Criteria | LLM 1 | LLM 2 | LLM 3 | Best |
|----------|-------|-------|-------|------|
| Honest | Y | N | Y | LLM 1/3 |

### Layer 5: Infra
| Criteria | LLM 1 | LLM 2 | LLM 3 | Best |
|----------|-------|-------|-------|------|
| Specificity | 3 | 3 | 4 | LLM 3 |

### Layer 6: Scale
| Criteria | LLM 1 | LLM 2 | LLM 3 | Best |
|----------|-------|-------|-------|------|
| Specificity | 4 | 3 | 5 | LLM 3 |

## Overall Verdict

| Dimension | Winner | Why |
|----------|--------|-----|
| Most technical | LLM 3 | Most detailed |
| Best tech names | LLM 3 | Real tools |
| Least hallucination | LLM 1 | Conservative |
| Best insight | LLM 3 | Strong analysis |
| Structure | LLM 1 | Clean |
| Speed | LLM 2 | Fast |

## Key Observation
Claude provided deeper reasoning and challenges, ChatGPT gave better structure, and Gemini was faster but more generic.
